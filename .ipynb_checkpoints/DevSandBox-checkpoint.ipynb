{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import io\n",
    "import os\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "\n",
    "from mobiledet.models.keras_yolo import (preprocess_true_boxes,\n",
    "                                     yolo_eval, yolo_head, yolo_loss)\n",
    "from mobiledet.utils.draw_boxes import draw_boxes\n",
    "from mobiledet.models.keras_darknet19 import darknet19\n",
    "import argparse\n",
    "import io\n",
    "import os\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "import cv2\n",
    "import copy\n",
    "\n",
    "from mobiledet.models.keras_yolo import (preprocess_true_boxes, yolo_body_darknet19,\n",
    "                                     yolo_body_mobilenet, yolo_eval, yolo_head, yolo_loss)\n",
    "from mobiledet.utils.draw_boxes import draw_boxes\n",
    "from mobiledet.utils import read_voc_datasets_train_batch, brightness_augment, augment_image\n",
    "from mobiledet.models.keras_yolo import yolo_get_detector_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_H = 608\n",
    "IMAGE_W = 608\n",
    "\n",
    "FEAT_W = IMAGE_W / 32\n",
    "FEAT_H = IMAGE_H / 32\n",
    "\n",
    "YOLO_ANCHORS = np.array(\n",
    "    ((0.57273, 0.677385), (1.87446, 2.06253), (3.33843, 5.47434),\n",
    "     (7.88282, 3.52778), (9.77052, 9.16828)))\n",
    "anchors = YOLO_ANCHORS \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_classes_path='model_data/drone_classes.txt'\n",
    "\n",
    "with open(drone_classes_path) as f:\n",
    "    drone_class_names = f.readlines()\n",
    "drone_class_names = [c.strip() for c in drone_class_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '~/data/PascalVOC/VOCdevkit/pascal_voc_07_12.hdf5'\n",
    "classes_path='model_data/pascal_classes.txt'\n",
    "\n",
    "voc_path = os.path.expanduser(data_path)\n",
    "with open(classes_path) as f:\n",
    "    class_names = f.readlines()\n",
    "class_names = [c.strip() for c in class_names]\n",
    "voc = h5py.File(voc_path, 'r')\n",
    "num_training_data =  voc['train/boxes'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'boxes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2bb1f8385ce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mH5_BOXES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train/boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mH5_IMAGES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train/images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtotal_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'boxes' is not defined"
     ]
    }
   ],
   "source": [
    "H5_BOXES = np.array(voc['train/boxes'])\n",
    "H5_IMAGES = np.array(voc['train/images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx =  1 #np.random.choice(total_data, replace=False)\n",
    "\n",
    "img_cv = PIL.Image.open(io.BytesIO(images[idx]))\n",
    "image_data = np.array(img_cv, dtype=np.uint8)\n",
    "\n",
    "bboxes1 = boxes[idx].reshape(-1,5)\n",
    "\n",
    "image1 = cv2.cvtColor(image_data, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "\n",
    "image_data, bboxes1 = read_voc_datasets_train_batch(H5_IMAGES, H5_BOXES, class_names, drone_class_names)\n",
    "\n",
    "x,y = augment_image(image_data, bboxes1, 608, 608, jitter=True)\n",
    "\n",
    "for box in y:\n",
    "    cv2.rectangle(x,(int(box[1]),int(box[2])),(int(box[3]),int(box[4])),(0,255,0),2)\n",
    "    \n",
    "plt.imshow(x/255.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_images = []\n",
    "batch_boxes = []\n",
    "\n",
    "for i in range(BATCH_SIZE):        \n",
    "    image_data, bboxes = read_voc_datasets_train_batch(H5_IMAGES, H5_BOXES, class_names, drone_class_names)\n",
    "    image_data, bboxes = augment_image(image_data, bboxes, IMAGE_H, IMAGE_W, jitter=True)\n",
    "    orig_size = np.array([image_data.shape[1], image_data.shape[0]])\n",
    "    orig_size = np.expand_dims(orig_size, axis=0)\n",
    "    image_data /= 255.\n",
    "    batch_images.append(image_data)\n",
    "\n",
    "    boxes = bboxes.reshape((-1, 5))\n",
    "    boxes_xy = 0.5 * (boxes[:, 3:5] + boxes[:, 1:3])\n",
    "    boxes_wh = boxes[:, 3:5] - boxes[:, 1:3]\n",
    "    boxes_xy = boxes_xy / orig_size\n",
    "    boxes_wh = boxes_wh / orig_size\n",
    "    boxes = np.concatenate((boxes_xy, boxes_wh, boxes[:, 0:1]), axis=1)\n",
    "    batch_boxes.append(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the max number of boxes\n",
    "max_boxes = 0\n",
    "for boxz in batch_boxes:\n",
    "    if boxz.shape[0] > max_boxes:\n",
    "        max_boxes = boxz.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add zero pad for training\n",
    "for i, boxz in enumerate(batch_boxes):\n",
    "    if boxz.shape[0]  < max_boxes:\n",
    "        zero_padding = np.zeros((max_boxes-boxz.shape[0], 5), dtype=np.float32)\n",
    "        batch_boxes[i] = np.vstack((boxz, zero_padding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_from_hdf5():\n",
    "    anchors = YOLO_ANCHORS \n",
    "    total_count = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    num_img = total_data\n",
    "    if True:\n",
    "        batch_images = []\n",
    "        batch_boxes = []\n",
    "        \n",
    "        for i in range(BATCH_SIZE):        \n",
    "            image_data, bboxes = read_voc_datasets_train_batch(H5_IMAGES, H5_BOXES, class_names, drone_class_names)\n",
    "            image_data, bboxes = augment_image(image_data, bboxes, IMAGE_H, IMAGE_W, jitter=True)\n",
    "            orig_size = np.array([image_data.shape[1], image_data.shape[0]])\n",
    "            orig_size = np.expand_dims(orig_size, axis=0)\n",
    "            image_data /= 255.\n",
    "            batch_images.append(image_data)\n",
    "            \n",
    "            boxes = bboxes.reshape((-1, 5))\n",
    "            boxes_xy = 0.5 * (boxes[:, 3:5] + boxes[:, 1:3])\n",
    "            boxes_wh = boxes[:, 3:5] - boxes[:, 1:3]\n",
    "            boxes_xy = boxes_xy / orig_size\n",
    "            boxes_wh = boxes_wh / orig_size\n",
    "            boxes = np.concatenate((boxes_xy, boxes_wh, boxes[:, 0:1]), axis=1)\n",
    "            batch_boxes.append(boxes)\n",
    "\n",
    "        \n",
    "        # find the max number of boxes\n",
    "        max_boxes = 0\n",
    "        for boxz in batch_boxes:\n",
    "            if boxz.shape[0] > max_boxes:\n",
    "                max_boxes = boxz.shape[0]\n",
    "        \n",
    "        # add zero pad for training\n",
    "        for i, boxz in enumerate(batch_boxes):\n",
    "            if boxz.shape[0]  < max_boxes:\n",
    "                zero_padding = np.zeros( (max_boxes-boxz.shape[0], 5), dtype=np.float32)\n",
    "                batch_boxes[i] = np.vstack((boxz, zero_padding))\n",
    "\n",
    "                    \n",
    "        batch_images = np.array(batch_images)\n",
    "        batch_boxes = np.array(batch_boxes)\n",
    "        \n",
    "        detectors_mask, matching_true_boxes = yolo_get_detector_mask(batch_boxes, anchors, model_shape=[608, 608])\n",
    "        X_train = [batch_images, batch_boxes, detectors_mask, matching_true_boxes]\n",
    "        y_train = np.zeros(len(batch_images))\n",
    "        return X_train, y_train\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Images, Boxes = read_voc_datasets_train_batch(voc_path, batch_size=BATCH_SIZE)\n",
    "# detectors_mask, matching_true_boxes = get_detector_mask(Boxes, anchors)\n",
    "# X_train = [Images, Boxes, detectors_mask, matching_true_boxes]\n",
    "# y_train = np.zeros(len(Images))\n",
    "X_train, y_train = flow_from_hdf5() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobiledet.models.keras_yolo import (preprocess_true_boxes, yolo_body_darknet19,\n",
    "                                     yolo_body_mobilenet, yolo_eval, yolo_head, yolo_loss)\n",
    "from mobiledet.utils.draw_boxes import draw_boxes\n",
    "\n",
    "detectors_mask_shape = (19, 19, 5, 1)\n",
    "matching_boxes_shape = (19, 19, 5, 5)\n",
    "\n",
    "# Create model input layers.\n",
    "image_input = Input(shape=(608, 608, 3))\n",
    "boxes_input = Input(shape=(None, 5))\n",
    "detectors_mask_input = Input(shape=detectors_mask_shape)\n",
    "matching_boxes_input = Input(shape=matching_boxes_shape)\n",
    "\n",
    "# Create model body.\n",
    "yolo_model = yolo_body_darknet19(image_input, len(anchors), len(class_names))\n",
    "topless_yolo = Model(yolo_model.input, yolo_model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda, Conv2D\n",
    "from keras.models import load_model, Model\n",
    "\n",
    "final_layer = Conv2D(len(anchors)*(5+len(class_names)), (1, 1), activation='linear')(topless_yolo.output)\n",
    "model_body = Model(image_input, final_layer)\n",
    "with tf.device('/cpu:0'):\n",
    "    # TODO: Replace Lambda with custom Keras layer for loss.\n",
    "    model_loss = Lambda(\n",
    "        yolo_loss,\n",
    "        output_shape=(1, ),\n",
    "        name='yolo_loss',\n",
    "        arguments={'anchors': anchors,\n",
    "                   'num_classes': len(class_names)})([\n",
    "                       model_body.output, boxes_input,\n",
    "                       detectors_mask_input, matching_boxes_input\n",
    "                   ])\n",
    "\n",
    "model = Model(\n",
    "    [model_body.input, boxes_input, detectors_mask_input,\n",
    "     matching_boxes_input], model_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss={\n",
    "        'yolo_loss': lambda y_true, y_pred: y_pred\n",
    "    })  # This is a hack to use the custom loss function in the last layer.\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"trained_stage_3_best.h5\", monitor='val_loss',\n",
    "                             save_weights_only=True, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=15, verbose=1, mode='auto')\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          validation_split=0.1,\n",
    "          batch_size=1,\n",
    "          epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
